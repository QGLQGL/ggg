{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "* **1. Introduction**\n",
    "* **2. Data preparation**\n",
    "    * 2.1 Load data\n",
    "    * 2.2 Check for null and missing values\n",
    "    * 2.3 Normalization\n",
    "    * 2.4 Reshape\n",
    "    * 2.5 Label encoding\n",
    "    * 2.6 Split training and valdiation set\n",
    "* **3. CNN**\n",
    "\n",
    "* **4. Evaluate the model**\n",
    "\n",
    "* **5. Prediction and submition**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb88b372-a6e5-40c8-a1c6-c03799165490",
    "_uuid": "e9aff3cf1bb8daa73bec67b970d12195677679f3"
   },
   "source": [
    "# 1. Introduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d2fb3e6-ab71-4974-b5a2-4af1ebdb99f4",
    "_execution_state": "idle",
    "_uuid": "86061d98eccaa02efe0dab0fa3884e71fcf4c310"
   },
   "source": [
    "# 2. Data preparation\n",
    "## 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>填写<<<< 利用pandas的load_csv函数，读取我们的train 和 test数据集合 变量已经给出 >>>>>填写<<<< ######\n",
    "train = pd.read_csv(\"11.04 RNN_LSTM\\作业\\subset_train.csv\")\n",
    "test = pd.read_csv(\"11.04 RNN_LSTM\\作业\\Small_test.csv\")\n",
    "#####train validation test(完全独立的，与训练过程无关的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4195</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4196</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4197</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4198</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4199</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4200 rows × 784 columns</p>\n</div>",
      "text/plain": "      pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0          0       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          0       0       0       0       0       0       0       0       0   \n3          0       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n4195       0       0       0       0       0       0       0       0       0   \n4196       0       0       0       0       0       0       0       0       0   \n4197       0       0       0       0       0       0       0       0       0   \n4198       0       0       0       0       0       0       0       0       0   \n4199       0       0       0       0       0       0       0       0       0   \n\n      pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0          0  ...         0         0         0         0         0         0   \n1          0  ...         0         0         0         0         0         0   \n2          0  ...         0         0         0         0         0         0   \n3          0  ...         0         0         0         0         0         0   \n4          0  ...         0         0         0         0         0         0   \n...      ...  ...       ...       ...       ...       ...       ...       ...   \n4195       0  ...         0         0         0         0         0         0   \n4196       0  ...         0         0         0         0         0         0   \n4197       0  ...         0         0         0         0         0         0   \n4198       0  ...         0         0         0         0         0         0   \n4199       0  ...         0         0         0         0         0         0   \n\n      pixel780  pixel781  pixel782  pixel783  \n0            0         0         0         0  \n1            0         0         0         0  \n2            0         0         0         0  \n3            0         0         0         0  \n4            0         0         0         0  \n...        ...       ...       ...       ...  \n4195         0         0         0         0  \n4196         0         0         0         0  \n4197         0         0         0         0  \n4198         0         0         0         0  \n4199         0         0         0         0  \n\n[4200 rows x 784 columns]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>>>>填写<<<< 利用pandas的header选择，将label列传递给Y_train >>>>>填写<<<< \n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "Y_test = test['label']\n",
    "# 因为train.csv中，第一列label在上述代码已经传递给Y_label，这里对于x_train 我们不需要训练集的第一列 #####\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "X_test = test.drop(labels = [\"label\"],axis = 1)\n",
    "# 释放内存\n",
    "\n",
    "X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5aea4062-1790-4987-b739-c4bebd79030f",
    "_uuid": "b7b1b1d36243c885e57374c8b60c5a7e10abe922"
   },
   "source": [
    "## We have similar counts for the 10 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b7d4b66-a140-4fcc-a889-bcef007c880a",
    "_uuid": "5d77934302869925c19128c77e247b3c8ca84d71"
   },
   "source": [
    "## 2.2 Check for null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count       784\nunique        1\ntop       False\nfreq        784\ndtype: object"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查训练数据是否有空值\n",
    "X_train.isnull().any().describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count       784\nunique        1\ntop       False\nfreq        784\ndtype: object"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>>>填写<<<< 检查训练数据是否有空值 >>>>填写<<<< ###\n",
    "X_test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09d04cae-4245-4659-85dd-ef48531da295",
    "_uuid": "c0bee59691c2df0b275c78e38e7f9907d02ac038"
   },
   "source": [
    "I check for corrupted images (missing values inside).\n",
    "\n",
    "There is no missing values in the train and test dataset. So we can safely go ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6812040d-80ad-43d2-a571-275f4f20067b",
    "_uuid": "2954681f25f0dcbe986e6914396cdbce61db591f"
   },
   "source": [
    "## 2.3 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "159d5854-437a-4d0f-bc1e-fc3f7e43d178",
    "_uuid": "0ecf4b52510ab7957d0d4eb646c0aa1ba5986273"
   },
   "source": [
    "We perform a grayscale normalization to reduce the effect of illumination's differences. \n",
    "\n",
    "Moreover the CNN converg faster on [0..1] data than on [0..255].\n",
    "标准化，将灰度值 0-255 映射到0 - 1区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4200, 784)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "###### >>>填写<<< 标准化测试集合 #######\n",
    "X_test = X_test / 255.0\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7413df94-bcb9-4f75-b174-c127d4445766",
    "_uuid": "a66741bf1ac597094f3a3166877008feef27c519"
   },
   "source": [
    "## 2.3 Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4200, 28, 28)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>>>填写<<<<< 利用 reshape 函数， 将X_train变换成 (height = 28px, width = 28px , canal = 0) ######\n",
    "# CNN (batch=-1 取所有=4200, rows, cols, channels)\n",
    "X_train = X_train.values.reshape(-1,28,28)  # 训练集合是4200个，28*28 通道数为1的输入）\n",
    "                                            # （4200，28，28）\n",
    "#对于RNN 输入为3D 张量，尺寸为 (batch_size, timesteps, input_dim)。\n",
    "#X_train = X_train.values.reshape(-1,28,28,1)    \n",
    "X_test = X_test.values.reshape(-1,28,28) \n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8decd1ce-7b7e-431d-8458-eaca18e0e1f7",
    "_uuid": "f4fb5553e188d9956f5d8b3a5d275ab00ea667ce"
   },
   "source": [
    "Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices. \n",
    "\n",
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb422e2-bdec-444f-97a5-283a1e54bf2c",
    "_uuid": "39b7a31e843bac6b705461bcce89da216b91799e"
   },
   "source": [
    "## 2.5 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用0 1编码 将0-9数字标签编码成10维向量 (ex : 9 -> [0,0,0,0,0,0,0,0,0,1])\n",
    "##\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_test = to_categorical(Y_test, num_classes = 10)\n",
    "## one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae068bd8-b12e-4768-8a7e-0fc865dd7562",
    "_uuid": "dcfb688587dfc6feafd27442a3505e35dc01b82d"
   },
   "source": [
    "Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32152fc3-a570-4d64-8a7d-6c689a4acd33",
    "_uuid": "d8abbbf31483b94e1b29d07c4c8253d1311648a7"
   },
   "source": [
    "## 2.6 Split training and valdiation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集合按照9:1 分成训练集合 和验证集合 validation 10折交叉验证 10-fold validation  ####\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "adbeacf0-0dc0-4675-b2df-9c9663750f32",
    "_uuid": "60eed15ec5bc0d354385301789ecb8538fc02267"
   },
   "source": [
    "We can get a better sense for one of these examples by visualising the image and looking at the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples #x-train里面第一个sample的 0:最大 0:最大 0 [:,:,0] \n",
    "#g = plt.imshow(X_train[0][:,:,0],cmap='gray') #plt为什么把灰度可以生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "# 4. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "504fa00e-148c-4364-9b68-218b3aaedfdb",
    "_uuid": "7697570491420f957f6e4d3569d51410b5277250"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN 答案 ########\n",
    "batch_size = 200\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "from keras.layers import SimpleRNN,LSTM\n",
    "# 如果图片是28*32像素\n",
    "# timsteps = 32 / 28 都可以 \n",
    "#(timesteps, input_dim)   28个时间节点的，28个维vector     \n",
    "# keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n",
    "model = Sequential()\n",
    "model.add(LSTM(500, input_shape=(28,28), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(500))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 运行model.summary（）回答下列问题 第二天课上一起讨论 ####\n",
    "model.summary()\n",
    "## LSTM中的参数 跟simpleRNN比 什么变化，越多的参数会有什么结果？###\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#优化器  尝试使用不同的优化器 至少以下三种 在DL 一个调节的点\n",
    "## 中文参考 https://keras.io/zh/optimizers/\n",
    "\n",
    "## SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "## RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "## Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=0.0000001, decay=0.0)\n",
    "\n",
    "### 将模型compile 编译\n",
    "### 调节loss 参数，即loss function\n",
    "### mean_squared_error\n",
    "### categorical_crossentropy/为什么不用binary_crossentropy\n",
    "### 尝试用\n",
    "### \n",
    "### mean_absolute_error \n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "### training 过程中的 自动调节函数\n",
    "### Reduce LR On Plateau = 减少学习率，当某一个参数达到一个平台期 自动的 把上面优化器中的 lr 减小\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "#### LSTM 尝试用 sparse_categorical_crossentropy 看看有什么变化结果 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train, batch_size=batch_size,\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成学习曲线 和损失函数 随着epoch的变化曲线\n",
    "# 模型的学习效果怎么样？ 能找到适合的epoch吗？\n",
    "# 简单的评价标准应该用什么？\n",
    "# 尝试改变模型参数 生成不同的学习曲线 比较\n",
    "# 提示 从epoch> 优化器> 损失函数> 学习率> dropout有无 依次调试 \n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成10标签混淆矩阵\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 打印出认错的数字\n",
    "\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 3\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 9 errors \n",
    "most_important_errors = sorted_dela_errors[-9:]\n",
    "\n",
    "# Show the top 9 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional 画出roc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_score = model.predict(X_test)\n",
    "# 在前天的作业中 y_test Pandas下的DataFrame类型：y_test\n",
    "# 让数据为 Pandas DataFrame类型的话 调用/使用他 第i行第j列的数据:\n",
    "#  y_test.iloc[i,j]\n",
    "\n",
    "# 在今天的作业中，y_test是 numpy的 numarry数据类型\n",
    "# 让数据为numarray 类型的话 调用/使用他 第i行第j列的数据:\n",
    "# y_test[i,j]\n",
    "for i in range(num_classes):\n",
    "     fpr[i], tpr[i], _ = roc_curve(Y_test[:,i], y_score[:,i]) #\n",
    "    # AUC Area Under the Curve\n",
    "     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "#y_pred_keras = model.predict(X_test).ravel()\n",
    "##fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_pred_keras)\n",
    "#y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}